{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "#from sklearn import dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import torch\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "np.random.seed(12345)\n",
    "train_x = np.random.random((N,2)) * 2.0 - 1.0\n",
    "train_y = np.array([((train_x[:,0]**2+train_x[:,1]**2)<1) + 0,((train_x[:,0]**2+train_x[:,1]**2)>=1) + 0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_x[:,0],train_x[:,1],c=train_y[:,0],edgecolors='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(5), max_iter=100, alpha=1e-4,\n",
    "                    solver='lbfgs', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1,activation='logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(train_x, train_y)\n",
    "print(\"Training set score: %f\" % mlp.score(train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_x[:,0],train_x[:,1],c=predictions[:,0],edgecolors='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NG = 100\n",
    "gx, gy = np.meshgrid(np.linspace(-1, 1, NG),np.linspace(-1, 1, NG))\n",
    "fgx = gx.flatten()\n",
    "fgy = gy.flatten()\n",
    "grid = np.array([fgx,fgy]).T\n",
    "C = mlp.predict(grid)[:,0].reshape(NG,NG)\n",
    "plt.contourf(gx,gy,C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = mlp.coefs_[0]\n",
    "b = mlp.intercepts_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1)\n",
    "plt.axis((-1,1,-1,1))\n",
    "for i in range(5):\n",
    "    plt.plot(x,-(x*w[0][i]+b[i])/w[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras (tensorflow interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "D = Dense(10, input_shape=(2,), activation='relu')\n",
    "model.add(D)\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_x[:,0],train_x[:,1],c=predictions[:,0],edgecolors='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NG = 100\n",
    "gx, gy = np.meshgrid(np.linspace(-1, 1, NG),np.linspace(-1, 1, NG))\n",
    "fgx = gx.flatten()\n",
    "fgy = gy.flatten()\n",
    "grid = np.array([fgx,fgy]).T\n",
    "C = model.predict(grid)[:,0].reshape(NG,NG)\n",
    "plt.contourf(gx,gy,C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b = D.get_weights()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "Low level tool 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Layer 0 \n",
    "x0 = tf.constant( train_x  , dtype=tf.float32 )\n",
    "y0 = tf.constant( train_y , dtype=tf.float32 )\n",
    "\n",
    "# Layer 1\n",
    "m1 = tf.Variable( tf.random_uniform( [2,20] , minval=-0.9 , maxval=0.9 , dtype=tf.float32  ))\n",
    "b1 = tf.Variable( tf.random_uniform( [20]   , minval=-0.9 , maxval=0.9 , dtype=tf.float32  ))\n",
    "h1 = tf.sigmoid( tf.matmul( x0,m1 ) + b1 )\n",
    "\n",
    "# Layer 2\n",
    "m2 = tf.Variable( tf.random_uniform( [20,20] , minval=-0.9 , maxval=0.9 , dtype=tf.float32  ))\n",
    "b2 = tf.Variable( tf.random_uniform( [20]   , minval=-0.9 , maxval=0.9 , dtype=tf.float32  ))\n",
    "h2 = tf.sigmoid( tf.matmul( h1,m2 ) + b2 )\n",
    "\n",
    "# Layer 3\n",
    "m3 = tf.Variable( tf.random_uniform( [20,2] , minval=-0.9 , maxval=0.9 , dtype=tf.float32  ))\n",
    "b3 = tf.Variable( tf.random_uniform( [2]   , minval=-0.9 , maxval=0.9 , dtype=tf.float32  ))\n",
    "y_out = tf.sigmoid( tf.matmul( h2,m3 ) + b3 )\n",
    "\n",
    "\n",
    "### loss\n",
    "# loss : sum of the squares of y0 - y_out\n",
    "loss = tf.reduce_mean( tf.square( y0 - y_out ))\n",
    "\n",
    "# training step : gradient decent (1.0) to minimize loss\n",
    "train = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "\n",
    "\n",
    "### training\n",
    "C = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run( tf.global_variables_initializer() )\n",
    "    for step in range(10000) :\n",
    "        sess.run(train)\n",
    "    #print(y_out.eval())\n",
    "    results = sess.run([m1,b1,m2,b2,m3,b3,y_out,loss])\n",
    "    labels  = \"m1,b1,m2,b2,m3,b3,y_out,loss\".split(\",\")\n",
    "    '''\n",
    "    for label,result in zip(*(labels,results)) :\n",
    "        print(\"\")\n",
    "        print(label)\n",
    "        print(result)\n",
    "    '''\n",
    "    C = y_out.eval()\n",
    "\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = tf.constant( train_x, dtype=tf.float32 )\n",
    "H1 = tf.sigmoid( tf.matmul( X0,m1 ) + b1 )\n",
    "H2 = tf.sigmoid( tf.matmul( H1,m2 ) + b2 )\n",
    "y_est = tf.sigmoid( tf.matmul( H2,m3 ) + b3 )\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    y_est_v = sess.run(y_out)\n",
    "    #y_est_v = y_est.eval()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_est_v[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_x[:,0],train_x[:,1],c=C[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch\n",
    "by Justin Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.double\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "H = 10\n",
    "x = torch.from_numpy(train_x)\n",
    "y = torch.from_numpy(train_y)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(2, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, 2, device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 1000 == 999:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_x[:,0],train_x[:,1],c=y_pred.detach().numpy()[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "\n",
    "D_in = 2\n",
    "D_out = 2\n",
    "H = 10\n",
    "x = torch.from_numpy(train_x).float()\n",
    "y = torch.from_numpy(train_y).float()\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Use the optim package to define an Optimizer that will update the weights of\n",
    "# the model for us. Here we will use Adam; the optim package contains many other\n",
    "# optimization algorithms. The first argument to the Adam constructor tells the\n",
    "# optimizer which Tensors it should update.\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 1000 == 999:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_x[:,0],train_x[:,1],c=y_pred.detach().numpy()[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "np.random.seed(12345)\n",
    "train_x = np.random.random((N,2)) * 2.0 - 1.0\n",
    "cond = ((train_x[:,0]**2+train_x[:,1]**2)<1)  * ((train_x[:,0]**2+train_x[:,1]**2)>0.25)\n",
    "train_y = np.array([cond*1,1-cond*1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_x[:,0],train_x[:,1],c=train_y[:,0],edgecolors='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "D = Dense(10, input_shape=(2,), activation='relu',\n",
    "            kernel_regularizer=keras.regularizers.l1_l2(l1=1e-2, l2=1e-2),\n",
    "            bias_regularizer=keras.regularizers.l2(1e-2),\n",
    "            activity_regularizer=keras.regularizers.l2(1e-2))\n",
    "model.add(D)\n",
    "model.add(Dense(10, activation='relu',\n",
    "            kernel_regularizer=keras.regularizers.l1_l2(l1=1e-2, l2=1e-2),\n",
    "            bias_regularizer=keras.regularizers.l2(1e-2),\n",
    "            activity_regularizer=keras.regularizers.l2(1e-2)))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_shape=(2,),activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, epochs=1000, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(train_x)\n",
    "plt.scatter(train_x[:,0],train_x[:,1],c=predictions[:,0],edgecolors='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NG = 100\n",
    "gx, gy = np.meshgrid(np.linspace(-1, 1, NG),np.linspace(-1, 1, NG))\n",
    "fgx = gx.flatten()\n",
    "fgy = gy.flatten()\n",
    "grid = np.array([fgx,fgy]).T\n",
    "C = model.predict(grid)[:,0].reshape(NG,NG)\n",
    "plt.contourf(gx,gy,C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_shape=(2,),activation='relu',kernel_regularizer=keras.regularizers.l1_l2(l1=1e-4, l2=1e-4)))\n",
    "model.add(Dense(20,activation='relu',kernel_regularizer=keras.regularizers.l1_l2(l1=1e-4, l2=1e-4)))\n",
    "model.add(Dense(2, activation='sigmoid',kernel_regularizer=keras.regularizers.l1_l2(l1=1e-4, l2=1e-4)))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, epochs=1000, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(train_x)\n",
    "plt.scatter(train_x[:,0],train_x[:,1],c=predictions[:,0],edgecolors='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NG = 100\n",
    "gx, gy = np.meshgrid(np.linspace(-1, 1, NG),np.linspace(-1, 1, NG))\n",
    "fgx = gx.flatten()\n",
    "fgy = gy.flatten()\n",
    "grid = np.array([fgx,fgy]).T\n",
    "C = model.predict(grid)[:,0].reshape(NG,NG)\n",
    "plt.contourf(gx,gy,C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
