{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8OAjwuqjO4h4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import urllib.request\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, LSTM\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras\n",
        "import collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nd5bwQ5lO4h8"
      },
      "outputs": [],
      "source": [
        "hu = SnowballStemmer(\"hungarian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g_D5tpFO4h9",
        "outputId": "fb48bf49-249a-42e0-a88f-01957d77e780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ház játszot\n"
          ]
        }
      ],
      "source": [
        "print(hu.stem(\"házakban\"),hu.stem(\"játszott\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "owaXAT9DO4iM"
      },
      "outputs": [],
      "source": [
        "fr = SnowballStemmer(\"french\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIS8DqbuO4iM",
        "outputId": "c597cf3a-f667-482a-b049-e1c355fec4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oeuf parlent\n"
          ]
        }
      ],
      "source": [
        "print(fr.stem(\"oeufs\"),fr.stem(\"parlent\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0b6ggaQDO4iN"
      },
      "outputs": [],
      "source": [
        "de = SnowballStemmer(\"german\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnHgymZ0O4iO",
        "outputId": "c572fab8-8536-4d11-c717-d93963f1f4b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "buch gehabt\n"
          ]
        }
      ],
      "source": [
        "print(de.stem(\"Bücher\"),de.stem(\"gehabt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "C5JHgcFhO4iO"
      },
      "outputs": [],
      "source": [
        "en = SnowballStemmer('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4BuGoRpO4iP",
        "outputId": "32ef5e67-c011-4dc0-ce28-45190a68c07c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "held hous hous\n"
          ]
        }
      ],
      "source": [
        "print(en.stem(\"held\"),en.stem(\"houses\"),en.stem(\"house\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZX69dLZyO4iP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umeiAJ3MO4iQ"
      },
      "source": [
        "### regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_Qt-zQxO4iR",
        "outputId": "fa7ddb0d-ab1f-4c8f-acb8-bd14153c125d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hab\n"
          ]
        }
      ],
      "source": [
        "s = \"almahab\"\n",
        "res = re.search(r'hab',s)\n",
        "if res:\n",
        "    print(res.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gHze5CadO4iR"
      },
      "outputs": [],
      "source": [
        "#beginning\n",
        "res = re.search(r'^hab',\"ahabab\")\n",
        "if res:\n",
        "    print(res.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJtKSLi7O4iR",
        "outputId": "f432868c-cf67-47e5-ce91-c49193df05f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hab\n"
          ]
        }
      ],
      "source": [
        "#end\n",
        "res = re.search(r'hab$',s)\n",
        "if res:\n",
        "    print(res.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os7hat-wO4iS",
        "outputId": "f94baff1-eb1b-40fb-e1a7-52317dcfe923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\n",
            "XXlXmXXhXXbX\n",
            "haab\n",
            "XhXb\n",
            "alahaab\n",
            "almahaab\n"
          ]
        }
      ],
      "source": [
        "# . matches anything\n",
        "# * as many as possible but can also be zero\n",
        "# + as many as possible but at least 1\n",
        "# {n} exacly n\n",
        "# ? as few as possible\n",
        "s = \"almahaab\"\n",
        "print(re.sub(r\"a.*a\",\"\",s)) \n",
        "print(re.sub(r\"a*\",\"X\",s))\n",
        "print(re.sub(r\"a.{2}a\",\"\",s))\n",
        "print(re.sub(r\"a.*?a\",\"X\",s))\n",
        "print(re.sub(r\"a*m\",\"\",s))\n",
        "print(re.sub(r\"a+m\",\"\",s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu31xBrNO4iS",
        "outputId": "eb210669-8277-4448-d9ce-2cbc1596d88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "a\n",
            "aa\n"
          ]
        }
      ],
      "source": [
        "#find sequences of a\n",
        "pattern = re.compile(r\"a+\")\n",
        "for v in re.finditer(pattern, \"almahaab\"):\n",
        "    print(v.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNBok9acO4iT",
        "outputId": "05fb6258-6c85-478d-d0ba-49f089eef33c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alma\n",
            "aa\n"
          ]
        }
      ],
      "source": [
        "#there can be anything between two a\n",
        "pattern = re.compile(r\"a.*?a\")\n",
        "for v in re.finditer(pattern, \"almahaab\"):\n",
        "    print(v.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycDnUVyZO4iT",
        "outputId": "8db2f8ce-92ce-4672-d23a-d87547cd45ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alma\n",
            "labda\n"
          ]
        }
      ],
      "source": [
        "#starts with a or l ends with a and there is at least something in between \n",
        "pattern = re.compile(r\"[al].+?a\")\n",
        "for v in re.finditer(pattern, \"alma labda baa\"):\n",
        "    print(v.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcLakndjO4iU",
        "outputId": "c24717fb-b67c-4b40-e18b-d7c3a59df4f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alma\n"
          ]
        }
      ],
      "source": [
        "#same as before but the last character befor a is not a d\n",
        "pattern = re.compile(r\"[al].+?(?<!d)a\")\n",
        "for v in re.finditer(pattern, \"alma labda\"):\n",
        "    print(v.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGyLX8EOO4iU",
        "outputId": "e934e0be-7f7d-4631-9c64-7247af8fcb42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "205\n"
          ]
        }
      ],
      "source": [
        "s = \"I have 205 euros\"\n",
        "res = re.search(r'[0-9]+',s)\n",
        "if res:\n",
        "    print(res.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6tcpbgZO4iV",
        "outputId": "0d3f4523-76ce-48cb-9a7e-32a091410388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.14\n"
          ]
        }
      ],
      "source": [
        "s = \"The value of pi is 3.14.\"\n",
        "res = re.search(r'[0-9]*\\.?[0-9]+',s)\n",
        "if res:\n",
        "    print(res.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4ND0G_AO4iV",
        "outputId": "66eb9c5f-887c-4529-e443-8693c36e467a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.77e-11\n"
          ]
        }
      ],
      "source": [
        "s = \"The gravitational constant is 6.77e-11 m3kg−1s−2.\"\n",
        "res = re.search(r'[-+]?[0-9]*\\.?[0-9]+([eE][-+]?[0-9]+)?',s)\n",
        "if res:\n",
        "    print(res.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H3MS3jvO4iV",
        "outputId": "7242d2a1-c44a-416c-8988-1e306abc83c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 July 2014\n",
            "1 August 2014\n",
            "1 September 2014\n"
          ]
        }
      ],
      "source": [
        "s = \"1 July 2014\"\n",
        "res = re.search(r'[0-9]+ (July|August) [1-9][0-9]{3}',s)\n",
        "if res:\n",
        "    print(res.group())\n",
        "s = \"1 August 2014\"\n",
        "res = re.search(r'[0-9]+ (July|August) [1-9][0-9]{3}',s)\n",
        "if res:\n",
        "    print(res.group())\n",
        "s = \"1 September 2014\"\n",
        "res = re.search(r'1 ([A-Z][a-z]*) [1-9][0-9]{3}',s)\n",
        "if res:\n",
        "    print(res.group())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YrVohI8GO4iW",
        "outputId": "aa46c2ff-6b26-4a5f-bc7a-efac49628fc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'János, Török'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "name1 = \"Török János\"\n",
        "re.sub(r\"(.*) (.*)\",r\"\\2, \\1\",name1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovHC8CNVO4iW"
      },
      "source": [
        "### TASK 1\n",
        "Change date format using regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oCKSDEgHO4iX",
        "outputId": "f7adb298-0bca-46e8-bfb5-f38374714a2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Easter Sunday this year was 2022.04.17.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "date = \"Easter Sunday this year was 17.04.2022.\"\n",
        "#change date to yyyy.mm.dd format\n",
        "re.sub(r\"([0-9]{2})\\.([0-9]{2})\\.([1-9][0-9]{3})\",r\"\\3.\\2.\\1\",date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1xG-Hf_LO4iX"
      },
      "outputs": [],
      "source": [
        "s = \"Ez egy mondat. Ez egy másik. Ez pedig egy harmadik. Ma 23. éve nem iszom. \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8IikT51O4iX",
        "outputId": "77a3fcd4-06d5-4125-e974-de05552cbc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ez egy mondat. \n",
            "Ez egy másik. \n",
            "Ez pedig egy harmadik. \n",
            "Ma 23. \n"
          ]
        }
      ],
      "source": [
        "pattern = re.compile(r\"[A-Z].*?\\. \")\n",
        "for v in re.finditer(pattern, s):\n",
        "    print(v.group(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DaZgsXUrO4iX"
      },
      "outputs": [],
      "source": [
        "hp = \"\"\"\n",
        "Mr. and Mrs. Dursley, of number four, Privet Drive, \n",
        "were proud to say that they were perfectly normal, \n",
        "thank you very much. They were the last people you’d \n",
        "expect to be involved in anything strange or \n",
        "mysterious, because they just didn’t hold with such \n",
        "nonsense. \n",
        "\n",
        "Mr. Dursley was the director of a firm called \n",
        "Grunnings, which made drills. He was a big, beefy \n",
        "man with hardly any neck, although he did have a \n",
        "very large mustache. Mrs. Dursley was thin and \n",
        "blonde and had nearly twice the usual amount of \n",
        "neck, which came in very useful as she spent so \n",
        "much of her time craning over garden fences, spying \n",
        "on the neighbors. The Dursley s had a small son \n",
        "called Dudley and in their opinion there was no finer \n",
        "boy anywhere. \n",
        "\n",
        "The Dursleys had everything they wanted, but they \n",
        "also had a secret, and their greatest fear was that \n",
        "somebody would discover it. They didn’t think they \n",
        "could bear it if anyone found out about the Potters. \n",
        "Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t \n",
        "met for several years; in fact, Mrs. Dursley pretended \n",
        "she didn’t have a sister, because her sister and her \n",
        "good-for-nothing husband were as unDursleyish as it \n",
        "was possible to be. The Dursleys shuddered to think \n",
        "what the neighbors would say if the Potters arrived in \n",
        "the street. The Dursleys knew that the Potters had a \n",
        "small son, too, but they had never even seen him. \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "tYD_9rBEO4iY",
        "outputId": "a2219350-5e16-404d-a742-bf0210fd0f90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense. Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursley s had a small son called Dudley and in their opinion there was no finer boy anywhere. The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn’t think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#make a continuous text out of it (remove newline)\n",
        "HP = hp.replace(\"\\n\",\"\")\n",
        "HP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVIF7yx2O4iY",
        "outputId": "09f5e599-547e-414b-8f73-2c18a2506588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. \n",
            "They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense. \n",
            "Mr. Dursley was the director of a firm called Grunnings, which made drills. \n",
            "He was a big, beefy man with hardly any neck, although he did have a very large mustache. \n",
            "Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. \n",
            "The Dursley s had a small son called Dudley and in their opinion there was no finer boy anywhere. \n",
            "The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. \n",
            "They didn’t think they could bear it if anyone found out about the Potters. \n",
            "Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. \n",
            "The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. \n",
            "The Dursleys knew that the Potters had a small son, too, but they had never even seen him. \n"
          ]
        }
      ],
      "source": [
        "#Finds sentences. The problem is that 'Mr.' looks like the end of a sentence and it isn't.\n",
        "pattern = re.compile(r\"[A-Z].*?(?<!Mr|Dr)(?<!Mrs)\\. \")\n",
        "for v in re.finditer(pattern, HP):\n",
        "    print(v.group(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9AlylyOmO4iY"
      },
      "outputs": [],
      "source": [
        "#Get full HP1\n",
        "url = \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%201%20-%20The%20Philosopher's%20Stone.txt\"\n",
        "f = urllib.request.urlopen(url)\n",
        "myfile = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M12zoCUpO4iZ",
        "outputId": "b703d27a-a738-44b7-a581-ed693e47e28d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "492161"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "len(myfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSzbgByWO4iZ",
        "outputId": "e18f147c-a8d2-4564-cc04-91d74fc1b66d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytes"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "type(myfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "T0K8u-kMO4iZ"
      },
      "outputs": [],
      "source": [
        "#convert it to utf8, remove newlines, quotation marks and page footer\n",
        "hp = myfile.decode(\"utf-8\").replace(\"\\n\",\"\").replace(\"”\",\"\")\n",
        "HP = re.sub(r\"Page \\| .*? Harry Potter and the Philosophers Stone - J.K. Rowling \",\"\",hp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js4wf4k1O4iZ",
        "outputId": "1c5a3c9a-34e0-46d9-de28-4d8b7ae4f796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. \n",
            "- They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense. \n",
            "- Mr. Dursley was the director of a firm called Grunnings, which made drills. \n",
            "- He was a big, beefy man with hardly any neck, although he did have a very large mustache. \n",
            "- Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. \n",
            "- The Dursley s had a small son called Dudley and in their opinion there was no finer boy anywhere. \n",
            "- The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. \n",
            "- They didn’t think they could bear it if anyone found out about the Potters. \n",
            "- Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. \n",
            "- The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. \n"
          ]
        }
      ],
      "source": [
        "#Let us see how it worked\n",
        "pattern = re.compile(r\"[A-Z][a-z].*?(?<!Mr|Dr)(?<!Mrs)[\\.\\?!] \")\n",
        "i = 0\n",
        "for v in re.finditer(pattern, HP):\n",
        "    print(\"-\",v.group(0))\n",
        "    i += 1\n",
        "    if i >=10: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnzdOF6oO4ia",
        "outputId": "d3eefc9c-a23c-41f9-c5c0-7d89417ef11a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "418304"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "len(HP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNARPFTZO4ib"
      },
      "source": [
        "### TASK 2\n",
        "Suggestion: create a list from the first 10 sentences in order to avoid extensive outputs, if works you can use an other array containing then all sentences.\n",
        "\n",
        "Write a loop which\n",
        "* goes through the sentences\n",
        "* splits the sentences to words\n",
        "* removes non-letter characters (w is the actual word):\n",
        "<pre>\n",
        "onlylett = re.compile('[^a-zA-Z]')\n",
        "onlylett.sub('', w)\n",
        "</pre>\n",
        "* print the stem of the word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the sentences\n",
        "pattern = re.compile(r\"[A-Z][a-z].*?(?<!Mr|Dr)(?<!Mrs)[\\.\\?!] \")\n",
        "sentences = []\n",
        "for v in re.finditer(pattern, HP):\n",
        "    sentences.append(v.group(0))\n",
        "\n",
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvS4lk_gYv6M",
        "outputId": "1705e6c8-5845-464c-ada8-8c4beb7ec102"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5969"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset = sentences"
      ],
      "metadata": {
        "id": "S1HLWoEnaAgB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_stems(sentence):\n",
        "  words = []\n",
        "  sentence_words = re.split(' ', sentence)\n",
        "  for w in sentence_words: \n",
        "    word = onlylett.sub('', w)\n",
        "    if word == '': continue\n",
        "    words.append(en.stem(onlylett.sub('', w)))\n",
        "  return words"
      ],
      "metadata": {
        "id": "S_eX4jPliRp7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "\n",
        "onlylett = re.compile('[^a-zA-Z]')\n",
        "\n",
        "for sentence in subset:\n",
        "  words = words + get_sentence_stems(sentence)\n",
        "\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykzRmxdYaeQb",
        "outputId": "fb019a53-1186-420e-87b4-791e7a48b126"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mr',\n",
              " 'and',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'of',\n",
              " 'number',\n",
              " 'four',\n",
              " 'privet',\n",
              " 'drive',\n",
              " 'were',\n",
              " 'proud',\n",
              " 'to',\n",
              " 'say',\n",
              " 'that',\n",
              " 'they',\n",
              " 'were',\n",
              " 'perfect',\n",
              " 'normal',\n",
              " 'thank',\n",
              " 'you',\n",
              " 'veri',\n",
              " 'much',\n",
              " 'they',\n",
              " 'were',\n",
              " 'the',\n",
              " 'last',\n",
              " 'peopl',\n",
              " 'youd',\n",
              " 'expect',\n",
              " 'to',\n",
              " 'be',\n",
              " 'involv',\n",
              " 'in',\n",
              " 'anyth',\n",
              " 'strang',\n",
              " 'or',\n",
              " 'mysteri',\n",
              " 'becaus',\n",
              " 'they',\n",
              " 'just',\n",
              " 'didnt',\n",
              " 'hold',\n",
              " 'with',\n",
              " 'such',\n",
              " 'nonsens',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'was',\n",
              " 'the',\n",
              " 'director',\n",
              " 'of',\n",
              " 'a',\n",
              " 'firm',\n",
              " 'call',\n",
              " 'grun',\n",
              " 'which',\n",
              " 'made',\n",
              " 'drill',\n",
              " 'he',\n",
              " 'was',\n",
              " 'a',\n",
              " 'big',\n",
              " 'beefi',\n",
              " 'man',\n",
              " 'with',\n",
              " 'hard',\n",
              " 'ani',\n",
              " 'neck',\n",
              " 'although',\n",
              " 'he',\n",
              " 'did',\n",
              " 'have',\n",
              " 'a',\n",
              " 'veri',\n",
              " 'larg',\n",
              " 'mustach',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'was',\n",
              " 'thin',\n",
              " 'and',\n",
              " 'blond',\n",
              " 'and',\n",
              " 'had',\n",
              " 'near',\n",
              " 'twice',\n",
              " 'the',\n",
              " 'usual',\n",
              " 'amount',\n",
              " 'of',\n",
              " 'neck',\n",
              " 'which',\n",
              " 'came',\n",
              " 'in',\n",
              " 'veri',\n",
              " 'use',\n",
              " 'as',\n",
              " 'she',\n",
              " 'spent',\n",
              " 'so',\n",
              " 'much',\n",
              " 'of',\n",
              " 'her',\n",
              " 'time',\n",
              " 'crane',\n",
              " 'over',\n",
              " 'garden',\n",
              " 'fenc',\n",
              " 'spi',\n",
              " 'on',\n",
              " 'the',\n",
              " 'neighbor',\n",
              " 'the',\n",
              " 'dursley',\n",
              " 's',\n",
              " 'had',\n",
              " 'a',\n",
              " 'small',\n",
              " 'son',\n",
              " 'call',\n",
              " 'dudley',\n",
              " 'and',\n",
              " 'in',\n",
              " 'their',\n",
              " 'opinion',\n",
              " 'there',\n",
              " 'was',\n",
              " 'no',\n",
              " 'finer',\n",
              " 'boy',\n",
              " 'anywher',\n",
              " 'the',\n",
              " 'dursley',\n",
              " 'had',\n",
              " 'everyth',\n",
              " 'they',\n",
              " 'want',\n",
              " 'but',\n",
              " 'they',\n",
              " 'also',\n",
              " 'had',\n",
              " 'a',\n",
              " 'secret',\n",
              " 'and',\n",
              " 'their',\n",
              " 'greatest',\n",
              " 'fear',\n",
              " 'was',\n",
              " 'that',\n",
              " 'somebodi',\n",
              " 'would',\n",
              " 'discov',\n",
              " 'it',\n",
              " 'they',\n",
              " 'didnt',\n",
              " 'think',\n",
              " 'they',\n",
              " 'could',\n",
              " 'bear',\n",
              " 'it',\n",
              " 'if',\n",
              " 'anyon',\n",
              " 'found',\n",
              " 'out',\n",
              " 'about',\n",
              " 'the',\n",
              " 'potter',\n",
              " 'mrs',\n",
              " 'potter',\n",
              " 'was',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'sister',\n",
              " 'but',\n",
              " 'they',\n",
              " 'hadnt',\n",
              " 'met',\n",
              " 'for',\n",
              " 'sever',\n",
              " 'year',\n",
              " 'in',\n",
              " 'fact',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'pretend',\n",
              " 'she',\n",
              " 'didnt',\n",
              " 'have',\n",
              " 'a',\n",
              " 'sister',\n",
              " 'becaus',\n",
              " 'her',\n",
              " 'sister',\n",
              " 'and',\n",
              " 'her',\n",
              " 'goodfornoth',\n",
              " 'husband',\n",
              " 'were',\n",
              " 'as',\n",
              " 'undursleyish',\n",
              " 'as',\n",
              " 'it',\n",
              " 'was',\n",
              " 'possibl',\n",
              " 'to',\n",
              " 'be',\n",
              " 'the',\n",
              " 'dursley',\n",
              " 'shudder',\n",
              " 'to',\n",
              " 'think',\n",
              " 'what',\n",
              " 'the',\n",
              " 'neighbor',\n",
              " 'would',\n",
              " 'say',\n",
              " 'if',\n",
              " 'the',\n",
              " 'potter',\n",
              " 'arriv',\n",
              " 'in',\n",
              " 'the',\n",
              " 'street',\n",
              " 'the',\n",
              " 'dursley',\n",
              " 'knew',\n",
              " 'that',\n",
              " 'the',\n",
              " 'potter',\n",
              " 'had',\n",
              " 'a',\n",
              " 'small',\n",
              " 'son',\n",
              " 'too',\n",
              " 'but',\n",
              " 'they',\n",
              " 'had',\n",
              " 'never',\n",
              " 'even',\n",
              " 'seen',\n",
              " 'him',\n",
              " 'this',\n",
              " 'boy',\n",
              " 'was',\n",
              " 'anoth',\n",
              " 'good',\n",
              " 'reason',\n",
              " 'for',\n",
              " 'keep',\n",
              " 'the',\n",
              " 'potter',\n",
              " 'away',\n",
              " 'they',\n",
              " 'didnt',\n",
              " 'want',\n",
              " 'dudley',\n",
              " 'mix',\n",
              " 'with',\n",
              " 'a',\n",
              " 'child',\n",
              " 'like',\n",
              " 'that',\n",
              " 'when',\n",
              " 'mr',\n",
              " 'and',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'woke',\n",
              " 'up',\n",
              " 'on',\n",
              " 'the',\n",
              " 'dull',\n",
              " 'gray',\n",
              " 'tuesday',\n",
              " 'our',\n",
              " 'stori',\n",
              " 'start',\n",
              " 'there',\n",
              " 'was',\n",
              " 'noth',\n",
              " 'about',\n",
              " 'the',\n",
              " 'cloudi',\n",
              " 'sky',\n",
              " 'outsid',\n",
              " 'to',\n",
              " 'suggest',\n",
              " 'that',\n",
              " 'strang',\n",
              " 'and',\n",
              " 'mysteri',\n",
              " 'thing',\n",
              " 'would',\n",
              " 'soon',\n",
              " 'be',\n",
              " 'happen',\n",
              " 'all',\n",
              " 'over',\n",
              " 'the',\n",
              " 'countri',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'hum',\n",
              " 'as',\n",
              " 'he',\n",
              " 'pick',\n",
              " 'out',\n",
              " 'his',\n",
              " 'most',\n",
              " 'bore',\n",
              " 'tie',\n",
              " 'for',\n",
              " 'work',\n",
              " 'and',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'gossip',\n",
              " 'away',\n",
              " 'happili',\n",
              " 'as',\n",
              " 'she',\n",
              " 'wrestl',\n",
              " 'a',\n",
              " 'scream',\n",
              " 'dudley',\n",
              " 'into',\n",
              " 'his',\n",
              " 'high',\n",
              " 'chair',\n",
              " 'none',\n",
              " 'of',\n",
              " 'them',\n",
              " 'notic',\n",
              " 'a',\n",
              " 'larg',\n",
              " 'tawni',\n",
              " 'owl',\n",
              " 'flutter',\n",
              " 'past',\n",
              " 'the',\n",
              " 'window',\n",
              " 'at',\n",
              " 'half',\n",
              " 'past',\n",
              " 'eight',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'pick',\n",
              " 'up',\n",
              " 'his',\n",
              " 'briefcas',\n",
              " 'peck',\n",
              " 'mrs',\n",
              " 'dursley',\n",
              " 'on',\n",
              " 'the',\n",
              " 'cheek',\n",
              " 'and',\n",
              " 'tri',\n",
              " 'to',\n",
              " 'kiss',\n",
              " 'dudley',\n",
              " 'goodby',\n",
              " 'but',\n",
              " 'miss',\n",
              " 'becaus',\n",
              " 'dudley',\n",
              " 'was',\n",
              " 'now',\n",
              " 'have',\n",
              " 'a',\n",
              " 'tantrum',\n",
              " 'and',\n",
              " 'throw',\n",
              " 'his',\n",
              " 'cereal',\n",
              " 'at',\n",
              " 'the',\n",
              " 'wall',\n",
              " 'littl',\n",
              " 'tyke',\n",
              " 'chortl',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'as',\n",
              " 'he',\n",
              " 'left',\n",
              " 'the',\n",
              " 'hous',\n",
              " 'he',\n",
              " 'got',\n",
              " 'into',\n",
              " 'his',\n",
              " 'car',\n",
              " 'and',\n",
              " 'back',\n",
              " 'out',\n",
              " 'of',\n",
              " 'number',\n",
              " 'four',\n",
              " 'drive',\n",
              " 'it',\n",
              " 'was',\n",
              " 'on',\n",
              " 'the',\n",
              " 'corner',\n",
              " 'of',\n",
              " 'the',\n",
              " 'street',\n",
              " 'that',\n",
              " 'he',\n",
              " 'notic',\n",
              " 'the',\n",
              " 'first',\n",
              " 'sign',\n",
              " 'of',\n",
              " 'someth',\n",
              " 'peculiar',\n",
              " 'a',\n",
              " 'cat',\n",
              " 'read',\n",
              " 'a',\n",
              " 'map',\n",
              " 'for',\n",
              " 'a',\n",
              " 'second',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'didnt',\n",
              " 'realiz',\n",
              " 'what',\n",
              " 'he',\n",
              " 'had',\n",
              " 'seen',\n",
              " 'then',\n",
              " 'he',\n",
              " 'jerk',\n",
              " 'his',\n",
              " 'head',\n",
              " 'around',\n",
              " 'to',\n",
              " 'look',\n",
              " 'again',\n",
              " 'there',\n",
              " 'was',\n",
              " 'a',\n",
              " 'tabbi',\n",
              " 'cat',\n",
              " 'stand',\n",
              " 'on',\n",
              " 'the',\n",
              " 'corner',\n",
              " 'of',\n",
              " 'privet',\n",
              " 'drive',\n",
              " 'but',\n",
              " 'there',\n",
              " 'wasnt',\n",
              " 'a',\n",
              " 'map',\n",
              " 'in',\n",
              " 'sight',\n",
              " 'what',\n",
              " 'could',\n",
              " 'he',\n",
              " 'have',\n",
              " 'been',\n",
              " 'think',\n",
              " 'of',\n",
              " 'it',\n",
              " 'must',\n",
              " 'have',\n",
              " 'been',\n",
              " 'a',\n",
              " 'trick',\n",
              " 'of',\n",
              " 'the',\n",
              " 'light',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'blink',\n",
              " 'and',\n",
              " 'stare',\n",
              " 'at',\n",
              " 'the',\n",
              " 'cat',\n",
              " 'it',\n",
              " 'stare',\n",
              " 'back',\n",
              " 'as',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'drove',\n",
              " 'around',\n",
              " 'the',\n",
              " 'corner',\n",
              " 'and',\n",
              " 'up',\n",
              " 'the',\n",
              " 'road',\n",
              " 'he',\n",
              " 'watch',\n",
              " 'the',\n",
              " 'cat',\n",
              " 'in',\n",
              " 'his',\n",
              " 'mirror',\n",
              " 'it',\n",
              " 'was',\n",
              " 'now',\n",
              " 'read',\n",
              " 'the',\n",
              " 'sign',\n",
              " 'that',\n",
              " 'said',\n",
              " 'privet',\n",
              " 'drive',\n",
              " 'no',\n",
              " 'look',\n",
              " 'at',\n",
              " 'the',\n",
              " 'sign',\n",
              " 'cat',\n",
              " 'couldnt',\n",
              " 'read',\n",
              " 'map',\n",
              " 'or',\n",
              " 'sign',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'gave',\n",
              " 'himself',\n",
              " 'a',\n",
              " 'littl',\n",
              " 'shake',\n",
              " 'and',\n",
              " 'put',\n",
              " 'the',\n",
              " 'cat',\n",
              " 'out',\n",
              " 'of',\n",
              " 'his',\n",
              " 'mind',\n",
              " 'as',\n",
              " 'he',\n",
              " 'drove',\n",
              " 'toward',\n",
              " 'town',\n",
              " 'he',\n",
              " 'thought',\n",
              " 'of',\n",
              " 'noth',\n",
              " 'except',\n",
              " 'a',\n",
              " 'larg',\n",
              " 'order',\n",
              " 'of',\n",
              " 'drill',\n",
              " 'he',\n",
              " 'was',\n",
              " 'hope',\n",
              " 'to',\n",
              " 'get',\n",
              " 'that',\n",
              " 'day',\n",
              " 'but',\n",
              " 'on',\n",
              " 'the',\n",
              " 'edg',\n",
              " 'of',\n",
              " 'town',\n",
              " 'drill',\n",
              " 'were',\n",
              " 'driven',\n",
              " 'out',\n",
              " 'of',\n",
              " 'his',\n",
              " 'mind',\n",
              " 'by',\n",
              " 'someth',\n",
              " 'els',\n",
              " 'as',\n",
              " 'he',\n",
              " 'sat',\n",
              " 'in',\n",
              " 'the',\n",
              " 'usual',\n",
              " 'morn',\n",
              " 'traffic',\n",
              " 'jam',\n",
              " 'he',\n",
              " 'couldnt',\n",
              " 'help',\n",
              " 'notic',\n",
              " 'that',\n",
              " 'there',\n",
              " 'seem',\n",
              " 'to',\n",
              " 'be',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'strang',\n",
              " 'dress',\n",
              " 'peopl',\n",
              " 'about',\n",
              " 'peopl',\n",
              " 'in',\n",
              " 'cloak',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'couldnt',\n",
              " 'bear',\n",
              " 'peopl',\n",
              " 'who',\n",
              " 'dress',\n",
              " 'in',\n",
              " 'funni',\n",
              " 'cloth',\n",
              " 'the',\n",
              " 'getup',\n",
              " 'you',\n",
              " 'saw',\n",
              " 'on',\n",
              " 'young',\n",
              " 'peopl',\n",
              " 'he',\n",
              " 'suppos',\n",
              " 'this',\n",
              " 'was',\n",
              " 'some',\n",
              " 'stupid',\n",
              " 'new',\n",
              " 'fashion',\n",
              " 'he',\n",
              " 'drum',\n",
              " 'his',\n",
              " 'finger',\n",
              " 'on',\n",
              " 'the',\n",
              " 'steer',\n",
              " 'wheel',\n",
              " 'and',\n",
              " 'his',\n",
              " 'eye',\n",
              " 'fell',\n",
              " 'on',\n",
              " 'a',\n",
              " 'huddl',\n",
              " 'of',\n",
              " 'these',\n",
              " 'weirdo',\n",
              " 'stand',\n",
              " 'quit',\n",
              " 'close',\n",
              " 'by',\n",
              " 'they',\n",
              " 'were',\n",
              " 'whisper',\n",
              " 'excit',\n",
              " 'togeth',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'was',\n",
              " 'enrag',\n",
              " 'to',\n",
              " 'see',\n",
              " 'that',\n",
              " 'a',\n",
              " 'coupl',\n",
              " 'of',\n",
              " 'them',\n",
              " 'werent',\n",
              " 'young',\n",
              " 'at',\n",
              " 'all',\n",
              " 'whi',\n",
              " 'that',\n",
              " 'man',\n",
              " 'had',\n",
              " 'to',\n",
              " 'be',\n",
              " 'older',\n",
              " 'than',\n",
              " 'he',\n",
              " 'was',\n",
              " 'and',\n",
              " 'wear',\n",
              " 'an',\n",
              " 'emeraldgreen',\n",
              " 'cloak',\n",
              " 'the',\n",
              " 'nerv',\n",
              " 'of',\n",
              " 'him',\n",
              " 'but',\n",
              " 'then',\n",
              " 'it',\n",
              " 'struck',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'that',\n",
              " 'this',\n",
              " 'was',\n",
              " 'probabl',\n",
              " 'some',\n",
              " 'silli',\n",
              " 'stunt',\n",
              " 'these',\n",
              " 'peopl',\n",
              " 'were',\n",
              " 'obvious',\n",
              " 'collect',\n",
              " 'for',\n",
              " 'someth',\n",
              " 'the',\n",
              " 'traffic',\n",
              " 'move',\n",
              " 'on',\n",
              " 'and',\n",
              " 'a',\n",
              " 'few',\n",
              " 'minut',\n",
              " 'later',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'arriv',\n",
              " 'in',\n",
              " 'the',\n",
              " 'grun',\n",
              " 'park',\n",
              " 'lot',\n",
              " 'his',\n",
              " 'mind',\n",
              " 'back',\n",
              " 'on',\n",
              " 'drill',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'alway',\n",
              " 'sat',\n",
              " 'with',\n",
              " 'his',\n",
              " 'back',\n",
              " 'to',\n",
              " 'the',\n",
              " 'window',\n",
              " 'in',\n",
              " 'his',\n",
              " 'offic',\n",
              " 'on',\n",
              " 'the',\n",
              " 'ninth',\n",
              " 'floor',\n",
              " 'if',\n",
              " 'he',\n",
              " 'hadnt',\n",
              " 'he',\n",
              " 'might',\n",
              " 'have',\n",
              " 'found',\n",
              " 'it',\n",
              " 'harder',\n",
              " 'to',\n",
              " 'concentr',\n",
              " 'on',\n",
              " 'drill',\n",
              " 'that',\n",
              " 'morn',\n",
              " 'he',\n",
              " 'didnt',\n",
              " 'see',\n",
              " 'the',\n",
              " 'owl',\n",
              " 'swoop',\n",
              " 'past',\n",
              " 'in',\n",
              " 'broad',\n",
              " 'daylight',\n",
              " 'though',\n",
              " 'peopl',\n",
              " 'down',\n",
              " 'in',\n",
              " 'the',\n",
              " 'street',\n",
              " 'did',\n",
              " 'they',\n",
              " 'point',\n",
              " 'and',\n",
              " 'gaze',\n",
              " 'openmouth',\n",
              " 'as',\n",
              " 'owl',\n",
              " 'after',\n",
              " 'owl',\n",
              " 'sped',\n",
              " 'overhead',\n",
              " 'most',\n",
              " 'of',\n",
              " 'them',\n",
              " 'had',\n",
              " 'never',\n",
              " 'seen',\n",
              " 'an',\n",
              " 'owl',\n",
              " 'even',\n",
              " 'at',\n",
              " 'nighttim',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'howev',\n",
              " 'had',\n",
              " 'a',\n",
              " 'perfect',\n",
              " 'normal',\n",
              " 'owlfre',\n",
              " 'morn',\n",
              " 'he',\n",
              " 'yell',\n",
              " 'at',\n",
              " 'five',\n",
              " 'differ',\n",
              " 'peopl',\n",
              " 'he',\n",
              " 'made',\n",
              " 'sever',\n",
              " 'import',\n",
              " 'telephon',\n",
              " 'call',\n",
              " 'and',\n",
              " 'shout',\n",
              " 'a',\n",
              " 'bit',\n",
              " 'more',\n",
              " 'he',\n",
              " 'was',\n",
              " 'in',\n",
              " 'a',\n",
              " 'veri',\n",
              " 'good',\n",
              " 'mood',\n",
              " 'until',\n",
              " 'lunchtim',\n",
              " 'when',\n",
              " 'he',\n",
              " 'thought',\n",
              " 'hed',\n",
              " 'stretch',\n",
              " 'his',\n",
              " 'leg',\n",
              " 'and',\n",
              " 'walk',\n",
              " 'across',\n",
              " 'the',\n",
              " 'road',\n",
              " 'to',\n",
              " 'buy',\n",
              " 'himself',\n",
              " 'a',\n",
              " 'bun',\n",
              " 'from',\n",
              " 'the',\n",
              " 'bakeri',\n",
              " 'hed',\n",
              " 'forgotten',\n",
              " 'all',\n",
              " 'about',\n",
              " 'the',\n",
              " 'peopl',\n",
              " 'in',\n",
              " 'cloak',\n",
              " 'until',\n",
              " 'he',\n",
              " 'pass',\n",
              " 'a',\n",
              " 'group',\n",
              " 'of',\n",
              " 'them',\n",
              " 'next',\n",
              " 'to',\n",
              " 'the',\n",
              " 'baker',\n",
              " 'he',\n",
              " 'eye',\n",
              " 'them',\n",
              " 'angrili',\n",
              " 'as',\n",
              " 'he',\n",
              " 'pass',\n",
              " 'he',\n",
              " 'didnt',\n",
              " 'know',\n",
              " 'whi',\n",
              " 'but',\n",
              " 'they',\n",
              " 'made',\n",
              " 'him',\n",
              " 'uneasi',\n",
              " 'this',\n",
              " 'bunch',\n",
              " 'were',\n",
              " 'whisper',\n",
              " 'excit',\n",
              " 'too',\n",
              " 'and',\n",
              " 'he',\n",
              " 'couldnt',\n",
              " 'see',\n",
              " 'a',\n",
              " 'singl',\n",
              " 'collect',\n",
              " 'tin',\n",
              " 'it',\n",
              " 'was',\n",
              " 'on',\n",
              " 'his',\n",
              " 'way',\n",
              " 'back',\n",
              " 'past',\n",
              " 'them',\n",
              " 'clutch',\n",
              " 'a',\n",
              " 'larg',\n",
              " 'doughnut',\n",
              " 'in',\n",
              " 'a',\n",
              " 'bag',\n",
              " 'that',\n",
              " 'he',\n",
              " 'caught',\n",
              " 'a',\n",
              " 'few',\n",
              " 'word',\n",
              " 'of',\n",
              " 'what',\n",
              " 'they',\n",
              " 'were',\n",
              " 'say',\n",
              " 'the',\n",
              " 'potter',\n",
              " 'that',\n",
              " 'right',\n",
              " 'that',\n",
              " 'what',\n",
              " 'i',\n",
              " 'heard',\n",
              " 'yes',\n",
              " 'their',\n",
              " 'son',\n",
              " 'harri',\n",
              " 'mr',\n",
              " 'dursley',\n",
              " 'stop',\n",
              " 'dead',\n",
              " 'fear',\n",
              " 'flood',\n",
              " 'him',\n",
              " 'he',\n",
              " 'look',\n",
              " 'back',\n",
              " 'at',\n",
              " 'the',\n",
              " 'whisper',\n",
              " 'as',\n",
              " 'if',\n",
              " 'he',\n",
              " 'want',\n",
              " 'to',\n",
              " 'say',\n",
              " 'someth',\n",
              " 'to',\n",
              " 'them',\n",
              " 'but',\n",
              " 'thought',\n",
              " 'better',\n",
              " 'of',\n",
              " 'it',\n",
              " 'he',\n",
              " 'dash',\n",
              " 'back',\n",
              " 'across',\n",
              " 'the',\n",
              " 'road',\n",
              " 'hurri',\n",
              " 'up',\n",
              " 'to',\n",
              " 'his',\n",
              " 'offic',\n",
              " 'snap',\n",
              " 'at',\n",
              " 'his',\n",
              " 'secretari',\n",
              " 'not',\n",
              " 'to',\n",
              " 'disturb',\n",
              " 'him',\n",
              " 'seiz',\n",
              " 'his',\n",
              " 'telephon',\n",
              " 'and',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U-6VDbvO4ib"
      },
      "source": [
        "### TASK 3\n",
        "* now instead of printing the stems collect them in an array\n",
        "* count the number of occurences of the stems (this can be done in an old fashioned way or using Counter https://pymotw.com/2/collections/counter.html\n",
        "* sort the stems according to occurence and print the top 250 stems\n",
        "* create a list with just the words in the above sorted order (the previous method should give you a dictionary, or a list of tuples)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = collections.Counter(words)\n",
        "sorted_words = []\n",
        "\n",
        "for word, _ in c.most_common():\n",
        "  sorted_words.append(word)\n",
        "\n",
        "sorted_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x14sHObjegJR",
        "outputId": "28d72048-6cbb-41b1-948c-f4305e516dad"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'and',\n",
              " 'to',\n",
              " 'a',\n",
              " 'he',\n",
              " 'harri',\n",
              " 'it',\n",
              " 'of',\n",
              " 'was',\n",
              " 'his',\n",
              " 'in',\n",
              " 'you',\n",
              " 'had',\n",
              " 'that',\n",
              " 'on',\n",
              " 'at',\n",
              " 'they',\n",
              " 'said',\n",
              " 'as',\n",
              " 'but',\n",
              " 'him',\n",
              " 'ron',\n",
              " 'look',\n",
              " 'hagrid',\n",
              " 'with',\n",
              " 'all',\n",
              " 'be',\n",
              " 'what',\n",
              " 'up',\n",
              " 'i',\n",
              " 'for',\n",
              " 'out',\n",
              " 'were',\n",
              " 'there',\n",
              " 'them',\n",
              " 'have',\n",
              " 'hermion',\n",
              " 'back',\n",
              " 'one',\n",
              " 'go',\n",
              " 'this',\n",
              " 'if',\n",
              " 'so',\n",
              " 'from',\n",
              " 'get',\n",
              " 'not',\n",
              " 'into',\n",
              " 'me',\n",
              " 'an',\n",
              " 'about',\n",
              " 'like',\n",
              " 'been',\n",
              " 'their',\n",
              " 'she',\n",
              " 'off',\n",
              " 'could',\n",
              " 'no',\n",
              " 'didnt',\n",
              " 'do',\n",
              " 'your',\n",
              " 'snape',\n",
              " 'down',\n",
              " 'know',\n",
              " 'got',\n",
              " 'her',\n",
              " 'professor',\n",
              " 'over',\n",
              " 'see',\n",
              " 'now',\n",
              " 'just',\n",
              " 'is',\n",
              " 'when',\n",
              " 'veri',\n",
              " 'dumbledor',\n",
              " 'tri',\n",
              " 'then',\n",
              " 'are',\n",
              " 'who',\n",
              " 'dudley',\n",
              " 'we',\n",
              " 'by',\n",
              " 'around',\n",
              " 'hed',\n",
              " 'well',\n",
              " 'time',\n",
              " 'how',\n",
              " 'malfoy',\n",
              " 'say',\n",
              " 'come',\n",
              " 'someth',\n",
              " 'head',\n",
              " 'right',\n",
              " 'uncl',\n",
              " 'eye',\n",
              " 'dont',\n",
              " 'vernon',\n",
              " 'potter',\n",
              " 'nevill',\n",
              " 'quirrel',\n",
              " 'turn',\n",
              " 'even',\n",
              " 'door',\n",
              " 'hand',\n",
              " 'dursley',\n",
              " 'want',\n",
              " 'where',\n",
              " 'never',\n",
              " 'onli',\n",
              " 'face',\n",
              " 'through',\n",
              " 'think',\n",
              " 'or',\n",
              " 'gryffindor',\n",
              " 'first',\n",
              " 'couldnt',\n",
              " 'more',\n",
              " 'would',\n",
              " 'befor',\n",
              " 'other',\n",
              " 'seem',\n",
              " 'mcgonagal',\n",
              " 'did',\n",
              " 'too',\n",
              " 'again',\n",
              " 'my',\n",
              " 'boy',\n",
              " 'still',\n",
              " 'yeh',\n",
              " 'thing',\n",
              " 'way',\n",
              " 'here',\n",
              " 'next',\n",
              " 'two',\n",
              " 'room',\n",
              " 'than',\n",
              " 'peopl',\n",
              " 'point',\n",
              " 'thought',\n",
              " 'though',\n",
              " 'stone',\n",
              " 'mr',\n",
              " 'which',\n",
              " 'good',\n",
              " 'tell',\n",
              " 'last',\n",
              " 'left',\n",
              " 'told',\n",
              " 'becaus',\n",
              " 'year',\n",
              " 'wasnt',\n",
              " 'some',\n",
              " 'hogwart',\n",
              " 'ask',\n",
              " 'sudden',\n",
              " 'oh',\n",
              " 'behind',\n",
              " 'start',\n",
              " 'hous',\n",
              " 'stop',\n",
              " 'long',\n",
              " 'dark',\n",
              " 'can',\n",
              " 'much',\n",
              " 'came',\n",
              " 'walk',\n",
              " 'us',\n",
              " 'will',\n",
              " 'take',\n",
              " 'toward',\n",
              " 'pull',\n",
              " 'went',\n",
              " 'away',\n",
              " 'wand',\n",
              " 'littl',\n",
              " 'himself',\n",
              " 'after',\n",
              " 'bit',\n",
              " 'open',\n",
              " 'onc',\n",
              " 'make',\n",
              " 'wizard',\n",
              " 'day',\n",
              " 'heard',\n",
              " 'yes',\n",
              " 'hes',\n",
              " 'keep',\n",
              " 'stare',\n",
              " 'let',\n",
              " 'ter',\n",
              " 'realli',\n",
              " 'put',\n",
              " 'whi',\n",
              " 'great',\n",
              " 'slytherin',\n",
              " 'made',\n",
              " 'school',\n",
              " 'found',\n",
              " 'owl',\n",
              " 'cloak',\n",
              " 'insid',\n",
              " 'find',\n",
              " 'aunt',\n",
              " 'wood',\n",
              " 'anyth',\n",
              " 'im',\n",
              " 'took',\n",
              " 'three',\n",
              " 'saw',\n",
              " 'book',\n",
              " 'weasley',\n",
              " 'watch',\n",
              " 'voic',\n",
              " 'petunia',\n",
              " 'quidditch',\n",
              " 'call',\n",
              " 'anoth',\n",
              " 'second',\n",
              " 'stand',\n",
              " 'everyon',\n",
              " 'knew',\n",
              " 'noth',\n",
              " 'ani',\n",
              " 'hadnt',\n",
              " 'move',\n",
              " 'yer',\n",
              " 'floor',\n",
              " 'ever',\n",
              " 'while',\n",
              " 'cant',\n",
              " 'letter',\n",
              " 'wall',\n",
              " 'must',\n",
              " 'mind',\n",
              " 'magic',\n",
              " 'near',\n",
              " 'seen',\n",
              " 'quick',\n",
              " 'end',\n",
              " 'black',\n",
              " 'filch',\n",
              " 'larg',\n",
              " 'lot',\n",
              " 'moment',\n",
              " 'felt',\n",
              " 'follow',\n",
              " 'dragon',\n",
              " 'happen',\n",
              " 'old',\n",
              " 'smile',\n",
              " 'night',\n",
              " 'broom',\n",
              " 'hard',\n",
              " 'use',\n",
              " 'everi',\n",
              " 'feet',\n",
              " 'rememb',\n",
              " 'hall',\n",
              " 'tabl',\n",
              " 'mrs',\n",
              " 'mirror',\n",
              " 'might',\n",
              " 'ground',\n",
              " 'gone',\n",
              " 'feel',\n",
              " 'notic',\n",
              " 'sat',\n",
              " 'almost',\n",
              " 'enough',\n",
              " 'air',\n",
              " 'minut',\n",
              " 'until',\n",
              " 'name',\n",
              " 'wouldnt',\n",
              " 'front',\n",
              " 'done',\n",
              " 'arm',\n",
              " 'fell',\n",
              " 'reach',\n",
              " 'cours',\n",
              " 'talk',\n",
              " 'whisper',\n",
              " 'muggl',\n",
              " 'bed',\n",
              " 'wait',\n",
              " 'without',\n",
              " 'our',\n",
              " 'work',\n",
              " 'high',\n",
              " 'sure',\n",
              " 'give',\n",
              " 'past',\n",
              " 'window',\n",
              " 'should',\n",
              " 'wonder',\n",
              " 'theyr',\n",
              " 'anyon',\n",
              " 'few',\n",
              " 'later',\n",
              " 'leg',\n",
              " 'word',\n",
              " 'better',\n",
              " 'hair',\n",
              " 'weve',\n",
              " 'voldemort',\n",
              " 'onto',\n",
              " 'need',\n",
              " 'troll',\n",
              " 'read',\n",
              " 'these',\n",
              " 'hundr',\n",
              " 'show',\n",
              " 'madam',\n",
              " 'life',\n",
              " 'under',\n",
              " 'alreadi',\n",
              " 'corridor',\n",
              " 'hold',\n",
              " 'gave',\n",
              " 'els',\n",
              " 'across',\n",
              " 'stood',\n",
              " 'same',\n",
              " 'theyd',\n",
              " 'mean',\n",
              " 'play',\n",
              " 'leav',\n",
              " 'hat',\n",
              " 'fire',\n",
              " 'pleas',\n",
              " 's',\n",
              " 'hope',\n",
              " 'pass',\n",
              " 'caught',\n",
              " 'sit',\n",
              " 'nose',\n",
              " 'famili',\n",
              " 'step',\n",
              " 'yet',\n",
              " 'train',\n",
              " 'side',\n",
              " 'fred',\n",
              " 'new',\n",
              " 'quit',\n",
              " 'alway',\n",
              " 'place',\n",
              " 'sound',\n",
              " 'stay',\n",
              " 'die',\n",
              " 'against',\n",
              " 'kept',\n",
              " 'hurri',\n",
              " 'knock',\n",
              " 'whole',\n",
              " 'glass',\n",
              " 'full',\n",
              " 'sort',\n",
              " 'broomstick',\n",
              " 'four',\n",
              " 'outsid',\n",
              " 'realiz',\n",
              " 'light',\n",
              " 'suppos',\n",
              " 'clear',\n",
              " 'ive',\n",
              " 'forward',\n",
              " 'own',\n",
              " 'forest',\n",
              " 'someon',\n",
              " 'both',\n",
              " 'drop',\n",
              " 'best',\n",
              " 'top',\n",
              " 'bad',\n",
              " 'hear',\n",
              " 'youv',\n",
              " 'run',\n",
              " 'each',\n",
              " 'white',\n",
              " 'perci',\n",
              " 'georg',\n",
              " 'team',\n",
              " 'half',\n",
              " 'help',\n",
              " 'care',\n",
              " 'kill',\n",
              " 'ten',\n",
              " 'father',\n",
              " 'mother',\n",
              " 'anyway',\n",
              " 'student',\n",
              " 'tree',\n",
              " 'peev',\n",
              " 'cat',\n",
              " 'morn',\n",
              " 'five',\n",
              " 'has',\n",
              " 'set',\n",
              " 'loud',\n",
              " 'live',\n",
              " 'week',\n",
              " 'silver',\n",
              " 'pocket',\n",
              " 'cold',\n",
              " 'gold',\n",
              " 'friend',\n",
              " 'listen',\n",
              " 'along',\n",
              " 'breath',\n",
              " 'empti',\n",
              " 'gringott',\n",
              " 'everyth',\n",
              " 'sorri',\n",
              " 'robe',\n",
              " 'mutter',\n",
              " 'answer',\n",
              " 'dog',\n",
              " 'round',\n",
              " 'red',\n",
              " 'troubl',\n",
              " 'note',\n",
              " 'o',\n",
              " 'fer',\n",
              " 'fluffi',\n",
              " 'funni',\n",
              " 'catch',\n",
              " 'heart',\n",
              " 'ill',\n",
              " 'youll',\n",
              " 'green',\n",
              " 'quiet',\n",
              " 'taken',\n",
              " 'lost',\n",
              " 'unicorn',\n",
              " 'flamel',\n",
              " 'norbert',\n",
              " 'strang',\n",
              " 'big',\n",
              " 'man',\n",
              " 'small',\n",
              " 'most',\n",
              " 'sight',\n",
              " 'worri',\n",
              " 'sir',\n",
              " 'christma',\n",
              " 'safe',\n",
              " 'cheer',\n",
              " 'mani',\n",
              " 'match',\n",
              " 'thank',\n",
              " 'usual',\n",
              " 'corner',\n",
              " 'close',\n",
              " 'dead',\n",
              " 'straight',\n",
              " 'carri',\n",
              " 'gasp',\n",
              " 'question',\n",
              " 'seat',\n",
              " 'shut',\n",
              " 'twin',\n",
              " 'potion',\n",
              " 'granger',\n",
              " 'goyl',\n",
              " 'except',\n",
              " 'werent',\n",
              " 'shout',\n",
              " 'dear',\n",
              " 'spot',\n",
              " 'doe',\n",
              " 'nois',\n",
              " 'rest',\n",
              " 'class',\n",
              " 'mouth',\n",
              " 'rais',\n",
              " 'speak',\n",
              " 'don',\n",
              " 'thousand',\n",
              " 'platform',\n",
              " 'blood',\n",
              " 'drive',\n",
              " 'expect',\n",
              " 'neck',\n",
              " 'reason',\n",
              " 'differ',\n",
              " 'snap',\n",
              " 'common',\n",
              " 'horribl',\n",
              " 'bright',\n",
              " 'abl',\n",
              " 'power',\n",
              " 'believ',\n",
              " 'jump',\n",
              " 'cupboard',\n",
              " 'between',\n",
              " 'either',\n",
              " 'shop',\n",
              " 'librari',\n",
              " 'world',\n",
              " 'tower',\n",
              " 'fang',\n",
              " 'send',\n",
              " 'guard',\n",
              " 'bludger',\n",
              " 'invis',\n",
              " 'youd',\n",
              " 'street',\n",
              " 'howev',\n",
              " 'chang',\n",
              " 'learn',\n",
              " 'final',\n",
              " 'sleep',\n",
              " 'far',\n",
              " 'cup',\n",
              " 'nervous',\n",
              " 'held',\n",
              " 'exact',\n",
              " 'shoulder',\n",
              " 'ball',\n",
              " 'parent',\n",
              " 'ear',\n",
              " 'touch',\n",
              " 'pile',\n",
              " 'ollivand',\n",
              " 'forget',\n",
              " 'crabb',\n",
              " 'castl',\n",
              " 'pick',\n",
              " 'miss',\n",
              " 'car',\n",
              " 'nice',\n",
              " 'isnt',\n",
              " 'giant',\n",
              " 'fast',\n",
              " 'yeah',\n",
              " 'hour',\n",
              " 'slowli',\n",
              " 'fat',\n",
              " 'began',\n",
              " 'manag',\n",
              " 'teacher',\n",
              " 'lie',\n",
              " 'those',\n",
              " 'key',\n",
              " 'pale',\n",
              " 'seven',\n",
              " 'cauldron',\n",
              " 'push',\n",
              " 'flitwick',\n",
              " 'ronan',\n",
              " 'scream',\n",
              " 'stupid',\n",
              " 'wear',\n",
              " 'direct',\n",
              " 'sinc',\n",
              " 'spoke',\n",
              " 'disappear',\n",
              " 'huge',\n",
              " 'roll',\n",
              " 'cri',\n",
              " 'laugh',\n",
              " 'given',\n",
              " 'crowd',\n",
              " 'pain',\n",
              " 'eat',\n",
              " 'field',\n",
              " 'wave',\n",
              " 'spell',\n",
              " 'quaffl',\n",
              " 'firenz',\n",
              " 'such',\n",
              " 'sign',\n",
              " 'togeth',\n",
              " 'dare',\n",
              " 'asleep',\n",
              " 'busi',\n",
              " 'scar',\n",
              " 'shook',\n",
              " 'furious',\n",
              " 'famous',\n",
              " 'gotten',\n",
              " 'alon',\n",
              " 'lock',\n",
              " 'wish',\n",
              " 'idea',\n",
              " 'snake',\n",
              " 'ceil',\n",
              " 'lean',\n",
              " 'ran',\n",
              " 'stick',\n",
              " 'mom',\n",
              " 'curs',\n",
              " 'hufflepuff',\n",
              " 'brother',\n",
              " 'snitch',\n",
              " 'number',\n",
              " 'shake',\n",
              " 'finger',\n",
              " 'afternoon',\n",
              " 'wont',\n",
              " 'fli',\n",
              " 'explain',\n",
              " 'er',\n",
              " 'shock',\n",
              " 'age',\n",
              " 'rather',\n",
              " 'lose',\n",
              " 'wild',\n",
              " 'climb',\n",
              " 'id',\n",
              " 'bottl',\n",
              " 'meet',\n",
              " 'game',\n",
              " 'kitchen',\n",
              " 'grab',\n",
              " 'money',\n",
              " 'mad',\n",
              " 'cross',\n",
              " 'won',\n",
              " 'hut',\n",
              " 'toad',\n",
              " 'goblin',\n",
              " 'hang',\n",
              " 'studi',\n",
              " 'seamus',\n",
              " 'lesson',\n",
              " 'sent',\n",
              " 'seeker',\n",
              " 'privet',\n",
              " 'secret',\n",
              " 'possibl',\n",
              " 'obvious',\n",
              " 'yell',\n",
              " 'import',\n",
              " 'forgotten',\n",
              " 'seiz',\n",
              " 'tonight',\n",
              " 'perhap',\n",
              " 'havent',\n",
              " 'wrong',\n",
              " 'threw',\n",
              " 'join',\n",
              " 'hate',\n",
              " 'crash',\n",
              " 'pier',\n",
              " 'surpris',\n",
              " 'somewher',\n",
              " 'chocol',\n",
              " 'line',\n",
              " 'boat',\n",
              " 'break',\n",
              " 'interest',\n",
              " 'frog',\n",
              " 'witch',\n",
              " 'sorcer',\n",
              " 'hurt',\n",
              " 'ghost',\n",
              " 'bane',\n",
              " 'fact',\n",
              " 'arriv',\n",
              " 'buy',\n",
              " 'finish',\n",
              " 'home',\n",
              " 'imagin',\n",
              " 'allow',\n",
              " 'instead',\n",
              " 'late',\n",
              " 'lay',\n",
              " 'slip',\n",
              " 'woman',\n",
              " 'youknowwho',\n",
              " 'lucki',\n",
              " 'silent',\n",
              " 'birthday',\n",
              " 'pair',\n",
              " 'paper',\n",
              " 'smell',\n",
              " 'mayb',\n",
              " 'hit',\n",
              " 'warn',\n",
              " 'terribl',\n",
              " 'tap',\n",
              " 'practic',\n",
              " 'dad',\n",
              " 'piec',\n",
              " 'packag',\n",
              " 'clap',\n",
              " 'third',\n",
              " 'nimbus',\n",
              " 'becam',\n",
              " 'nicola',\n",
              " 'exam',\n",
              " 'sister',\n",
              " 'met',\n",
              " 'throw',\n",
              " 'edg',\n",
              " 'bag',\n",
              " 'tea',\n",
              " 'angri',\n",
              " 'tail',\n",
              " 'twelv',\n",
              " 'eleven',\n",
              " 'pomfrey',\n",
              " 'true',\n",
              " 'land',\n",
              " 'bent',\n",
              " 'hell',\n",
              " 'london',\n",
              " 'swung',\n",
              " 'dream',\n",
              " 'knee',\n",
              " 'danger',\n",
              " 'remind',\n",
              " 'understand',\n",
              " 'matter',\n",
              " 'leapt',\n",
              " 'mistak',\n",
              " 'nearer',\n",
              " 'brought',\n",
              " 'cart',\n",
              " 'lead',\n",
              " 'nine',\n",
              " 'charli',\n",
              " 'card',\n",
              " 'classroom',\n",
              " 'save',\n",
              " 'flint',\n",
              " 'normal',\n",
              " 'twice',\n",
              " 'sever',\n",
              " 'sky',\n",
              " 'chair',\n",
              " 'jerk',\n",
              " 'excit',\n",
              " 'wide',\n",
              " 'yourself',\n",
              " 'middl',\n",
              " 'mark',\n",
              " 'odd',\n",
              " 'apart',\n",
              " 'decid',\n",
              " 'nasti',\n",
              " 'upstair',\n",
              " 'peer',\n",
              " 'beard',\n",
              " 'lamp',\n",
              " 'tight',\n",
              " 'pink',\n",
              " 'egg',\n",
              " 'thick',\n",
              " 'forc',\n",
              " 'bodi',\n",
              " 'wors',\n",
              " 'cake',\n",
              " 'joke',\n",
              " 'deep',\n",
              " 'speed',\n",
              " 'scare',\n",
              " 'girl',\n",
              " 'anythin',\n",
              " 'expel',\n",
              " 'row',\n",
              " 'vault',\n",
              " 'abov',\n",
              " 'wing',\n",
              " 'inch',\n",
              " 'reflect',\n",
              " 'hedwig',\n",
              " 'prefect',\n",
              " 'scabber',\n",
              " 'path',\n",
              " 'win',\n",
              " 'portrait',\n",
              " 'chaser',\n",
              " 'ahead',\n",
              " 'also',\n",
              " 'stori',\n",
              " 'soon',\n",
              " 'mention',\n",
              " 'today',\n",
              " 'grin',\n",
              " 'stuff',\n",
              " 'lip',\n",
              " 'agre',\n",
              " 'kind',\n",
              " 'narrow',\n",
              " 'albus',\n",
              " 'proper',\n",
              " 'real',\n",
              " 'trembl',\n",
              " 'somehow',\n",
              " 'nod',\n",
              " 'forehead',\n",
              " 'wed',\n",
              " 'ago',\n",
              " 'present',\n",
              " 'enter',\n",
              " 'case',\n",
              " 'easi',\n",
              " 'hide',\n",
              " 'wind',\n",
              " 'fall',\n",
              " 'flash',\n",
              " 'wander',\n",
              " 'flat',\n",
              " 'burst',\n",
              " 'heavi',\n",
              " 'coat',\n",
              " 'fight',\n",
              " 'pack',\n",
              " 'rock',\n",
              " 'silenc',\n",
              " 'hole',\n",
              " 'arent',\n",
              " 'flew',\n",
              " 'free',\n",
              " 'griphook',\n",
              " 'cover',\n",
              " 'feather',\n",
              " 'trunk',\n",
              " 'chamber',\n",
              " 'hooch',\n",
              " 'themselv',\n",
              " 'dive',\n",
              " 'fifti',\n",
              " 'crate',\n",
              " 'fear',\n",
              " 'pretend',\n",
              " 'gray',\n",
              " 'none',\n",
              " 'blink',\n",
              " 'swoop',\n",
              " 'clutch',\n",
              " 'tini',\n",
              " 'happi',\n",
              " 'crept',\n",
              " 'tall',\n",
              " 'blue',\n",
              " 'broken',\n",
              " 'size',\n",
              " 'howl',\n",
              " 'race',\n",
              " 'appear',\n",
              " 'rule',\n",
              " 'difficult',\n",
              " 'unwrap',\n",
              " 'sweater',\n",
              " 'becom',\n",
              " 'nobodi',\n",
              " 'holiday',\n",
              " 'smelt',\n",
              " 'tear',\n",
              " 'crack',\n",
              " 'mail',\n",
              " 'ignor',\n",
              " 'foot',\n",
              " 'sigh',\n",
              " 'eh',\n",
              " 'chanc',\n",
              " 'box',\n",
              " 'station',\n",
              " 'flame',\n",
              " 'hung',\n",
              " 'readi',\n",
              " 'jordan',\n",
              " 'staircas',\n",
              " 'bin',\n",
              " 'chess',\n",
              " 'proud',\n",
              " 'perfect',\n",
              " 'although',\n",
              " 'probabl',\n",
              " 'stretch',\n",
              " 'oclock',\n",
              " 'celebr',\n",
              " 'purpl',\n",
              " 'least',\n",
              " 'chuckl',\n",
              " 'bet',\n",
              " 'sharp',\n",
              " 'glanc',\n",
              " 'shot',\n",
              " 'broke',\n",
              " 'may',\n",
              " 'babi',\n",
              " 'wake',\n",
              " 'low',\n",
              " 'kick',\n",
              " 'rose',\n",
              " 'luck',\n",
              " 'plate',\n",
              " 'horror',\n",
              " 'ladi',\n",
              " 'shed',\n",
              " 'rat',\n",
              " 'ice',\n",
              " 'entranc',\n",
              " 'keeper',\n",
              " 'dure',\n",
              " 'rush',\n",
              " 'glad',\n",
              " 'toilet',\n",
              " 'water',\n",
              " 'whos',\n",
              " 'six',\n",
              " 'em',\n",
              " 'drink',\n",
              " 'tomorrow',\n",
              " 'sofa',\n",
              " 'ah',\n",
              " 'eager',\n",
              " 'fade',\n",
              " 'umbrella',\n",
              " 'leaki',\n",
              " 'twist',\n",
              " 'stool',\n",
              " 'pin',\n",
              " 'desper',\n",
              " 'lee',\n",
              " 'ravenclaw',\n",
              " 'player',\n",
              " 'draco',\n",
              " 'doesnt',\n",
              " 'turban',\n",
              " 'plant',\n",
              " 'norri',\n",
              " 'thin',\n",
              " 'spent',\n",
              " 'son',\n",
              " 'suggest',\n",
              " 'flutter',\n",
              " 'order',\n",
              " 'cloth',\n",
              " 'singl',\n",
              " 'grunt',\n",
              " 'complet',\n",
              " 'rattl',\n",
              " 'news',\n",
              " 'slam',\n",
              " 'midnight',\n",
              " 'twitch',\n",
              " 'known',\n",
              " 'click',\n",
              " 'person',\n",
              " 'frighten',\n",
              " 'calm',\n",
              " 'neither',\n",
              " 'trust',\n",
              " 'curious',\n",
              " 'cut',\n",
              " 'stair',\n",
              " 'hidden',\n",
              " 'televis',\n",
              " 'unless',\n",
              " 'pig',\n",
              " 'brown',\n",
              " 'relief',\n",
              " 'shouldnt',\n",
              " 'bought',\n",
              " 'moan',\n",
              " 'visit',\n",
              " 'slid',\n",
              " 'death',\n",
              " 'sometim',\n",
              " 'closer',\n",
              " 'breakfast',\n",
              " 'envelop',\n",
              " 'bill',\n",
              " 'parchment',\n",
              " 'storm',\n",
              " 'whistl',\n",
              " 'steal',\n",
              " 'drew',\n",
              " 'sausag',\n",
              " 'shadow',\n",
              " 'growl',\n",
              " 'quill',\n",
              " 'teeth',\n",
              " 'inde',\n",
              " 'halloween',\n",
              " 'ordinari',\n",
              " 'outta',\n",
              " 'barrier',\n",
              " 'delight',\n",
              " 'art',\n",
              " 'passageway',\n",
              " 'drag',\n",
              " 'earth',\n",
              " 'excus',\n",
              " 'charm',\n",
              " 'goe',\n",
              " 'compart',\n",
              " 'flavor',\n",
              " 'bean',\n",
              " 'underneath',\n",
              " 'longbottom',\n",
              " 'dean',\n",
              " 'bloodi',\n",
              " 'dormitori',\n",
              " 'dungeon',\n",
              " 'branch',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWpUklfrO4ic"
      },
      "source": [
        "### TASK 4\n",
        "* the following routine returns the position of the stem in the sorted list of the words (please note that it works with a list of words, wheras sorting the result of Counter results in a dictionary\n",
        " - w is the stem\n",
        " - sortedstemlist is the sorted list of stems\n",
        " - lim is a limit (integer), is a stem is lower in the rank than lim the function returns lim\n",
        "* Try it with lim=250 and words in and otside the top 250 (e.g. \"hogwart\", and above 250 e.g. \"stupid\")\n",
        "\n",
        "We need it to give words numbers. 250 will be the number of an unimportant word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6cZdLgqSO4ic"
      },
      "outputs": [],
      "source": [
        "def word_code(w,sortedstemlist,lim):\n",
        "    if w in sortedstemlist[:lim]:\n",
        "        return sortedstemlist.index(w)\n",
        "    else:\n",
        "        return(lim)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_code('drgbgive', sorted_words, 250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKul68-pgZgq",
        "outputId": "91d2c11b-25b6-4f88-8278-c88de11c4781"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dPLEypZO4ic"
      },
      "source": [
        "### TASK 5\n",
        "Create lists to train data\n",
        "* For each sentence go through the words with an index <code>i</code>\n",
        "* Generate word indices for words <code>i-2,i-1,i,i+1,i+2</code>, of course if index is out of range the result should be lim=250. The resulting indices are <code>i0,i1,i2,i3,i4</code>\n",
        "* (This is what you should do: For each word <code>i</code> remove the nonletter characters, get the stem then encode it with the word_code function, which returns <code>i0,i1,i2,i3,i4</code>)\n",
        "* Create an input list and an output list:\n",
        "<pre>\n",
        "if i2 < 250:\n",
        "    Xl.append([i0,i1,i3,i4])\n",
        "    yl.append(i2)\n",
        "</pre>\n",
        "(optional) You can use new indices for beginning and end of sentence, and nonexistent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xl = []\n",
        "yl = []\n",
        "\n",
        "for sentence in subset:\n",
        "  sentence_words = get_sentence_stems(sentence)\n",
        "  for i in range(2, len(sentence_words) - 2):\n",
        "    i0, i1, i2, i3, i4 = [word_code(w, sorted_words, 250) for w in sentence_words[i - 2: i + 3]]\n",
        "    if i2 < 250:\n",
        "      Xl.append([i0,i1,i3,i4])\n",
        "      yl.append(i2)"
      ],
      "metadata": {
        "id": "WhtwOdfagmKu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le_PZkIjO4in"
      },
      "source": [
        "### TASK 6\n",
        "Create a one or two layer dense network, input size is (4, 251), output size is 250, compile. Use flatten before the last layer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(Dense(units = 100, input_shape = (4, 251), activation = 'relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 250, activation = 'softmax'))\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY7xyflpjW6Z",
        "outputId": "d53c3a0d-9c60-4767-a87e-9030028c52da"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 4, 100)            25200     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 250)               100250    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 125,450\n",
            "Trainable params: 125,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imlqb6CRO4in"
      },
      "source": [
        "### TASK 7\n",
        "* convert our list to one hot encoding <code>to_categorical(Xl), to_categorical(yl)</code>\n",
        "* train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = to_categorical(Xl)\n",
        "Y = to_categorical(yl)\n",
        "\n",
        "model.fit(X, Y, batch_size = 40, epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFJ0a8F4ll4M",
        "outputId": "59c9e83f-8741-4c16-ad6e-18912263ebc2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "809/809 [==============================] - 7s 7ms/step - loss: 0.0444 - accuracy: 0.1011\n",
            "Epoch 2/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0206 - accuracy: 0.1654\n",
            "Epoch 3/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0196 - accuracy: 0.1925\n",
            "Epoch 4/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0192 - accuracy: 0.2074\n",
            "Epoch 5/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0189 - accuracy: 0.2155\n",
            "Epoch 6/20\n",
            "809/809 [==============================] - 6s 7ms/step - loss: 0.0187 - accuracy: 0.2220\n",
            "Epoch 7/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0187 - accuracy: 0.2265\n",
            "Epoch 8/20\n",
            "809/809 [==============================] - 5s 6ms/step - loss: 0.0186 - accuracy: 0.2289\n",
            "Epoch 9/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0186 - accuracy: 0.2305\n",
            "Epoch 10/20\n",
            "809/809 [==============================] - 6s 7ms/step - loss: 0.0185 - accuracy: 0.2308\n",
            "Epoch 11/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0185 - accuracy: 0.2316\n",
            "Epoch 12/20\n",
            "809/809 [==============================] - 6s 7ms/step - loss: 0.0185 - accuracy: 0.2328\n",
            "Epoch 13/20\n",
            "809/809 [==============================] - 6s 7ms/step - loss: 0.0185 - accuracy: 0.2339\n",
            "Epoch 14/20\n",
            "809/809 [==============================] - 6s 7ms/step - loss: 0.0185 - accuracy: 0.2333\n",
            "Epoch 15/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0185 - accuracy: 0.2337\n",
            "Epoch 16/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0186 - accuracy: 0.2347\n",
            "Epoch 17/20\n",
            "809/809 [==============================] - 6s 8ms/step - loss: 0.0186 - accuracy: 0.2338\n",
            "Epoch 18/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0186 - accuracy: 0.2350\n",
            "Epoch 19/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0186 - accuracy: 0.2349\n",
            "Epoch 20/20\n",
            "809/809 [==============================] - 5s 7ms/step - loss: 0.0186 - accuracy: 0.2345\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45bf863d10>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5hxPaELO4io"
      },
      "source": [
        "### TASK 8\n",
        "verify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dWX5gjeO4io",
        "outputId": "47dde4f7-a786-4362-83eb-e423785ece0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 123ms/step\n"
          ]
        }
      ],
      "source": [
        "s = [\"The\", \"Dursleys\", \"had\", \"everything\", \"they\"]\n",
        "a = [ word_code(en.stem(onlylett.sub('', s[0])),sorted_words,250),\n",
        "     word_code(en.stem(onlylett.sub('', s[1])),sorted_words,250),\n",
        "     word_code(en.stem(onlylett.sub('', s[3])),sorted_words,250),\n",
        "     word_code(en.stem(onlylett.sub('', s[4])),sorted_words,250)]\n",
        "b = to_categorical(a)\n",
        "res = model.predict(np.array([b]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH8xAFIaO4ip",
        "outputId": "b3e37906-5767-42f1-a638-ca2955a56d69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'was', 'had', 'of', 'the'], dtype='<U16')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "np.array(sorted_words)[(-res[0]).argsort()[:5]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y209IQiSO4ip",
        "outputId": "78949f24-7fb0-467b-d112-1b50b21da905"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20789923, 0.19742687, 0.08706977, 0.0725936, 0.020993423]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "sorted(res[0],reverse=True)[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7yBRg7LO4ip"
      },
      "source": [
        "## Task 9\n",
        " Predict next word:\n",
        " * The input data should be $L$ successive words. This time remove words with no code.\n",
        " * The target is the next word\n",
        " * Use an LSTM network to predict the next word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "w15b3wVoO4iq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5528b365-c048-4842-f5ab-c5ef4b5cb32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[140, 1, 103, 7, 32], [1, 103, 7, 32, 2], [103, 7, 32, 2, 87], [7, 32, 2, 87, 13], [32, 2, 87, 13, 16], [2, 87, 13, 16, 32], [87, 13, 16, 32, 11], [13, 16, 32, 11, 72], [16, 32, 0, 144, 135], [32, 0, 144, 135, 2]]\n",
            "[2, 87, 13, 16, 32, 11, 72, 162, 2, 26]\n"
          ]
        }
      ],
      "source": [
        "L = 5\n",
        "\n",
        "trainX = []\n",
        "trainY = []\n",
        "\n",
        "for sentence in subset:\n",
        "  sentence_words = get_sentence_stems(sentence)\n",
        "\n",
        "  # Get the codes under 250 of the sentence\n",
        "  sentence_codes = list(filter(lambda code: code < 250, [word_code(w, sorted_words, 250) for w in sentence_words]))\n",
        "\n",
        "  for i in range(L, len(sentence_codes)):\n",
        "    trainX.append(sentence_codes[i - L: i])\n",
        "    trainY.append(sentence_codes[i])\n",
        "\n",
        "print(trainX[:10])\n",
        "print(trainY[:10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(sorted_words)[trainX[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHMyHAJ90WnR",
        "outputId": "2e11f51d-6171-44d2-a342-666087032e3d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mr', 'and', 'dursley', 'of', 'were'], dtype='<U16')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(sorted_words)[trainY[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-SNbyODU1uQT",
        "outputId": "9440a92a-89be-4a08-f6d0-229d1fa5cb22"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(LSTM(120, input_shape=(L, 250)))\n",
        "model.add(Dense(units = 250, activation = 'softmax'))\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJwgbw4k10VC",
        "outputId": "70d974ba-3416-4041-9a6a-ea83432e5067"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 120)               178080    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 250)               30250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 208,330\n",
            "Trainable params: 208,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = to_categorical(trainX)\n",
        "Y = to_categorical(trainY)\n",
        "\n",
        "model.fit(X, Y, batch_size = 40, epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9XqVUqd2VUH",
        "outputId": "f03fd6e7-2285-4ebd-8cac-4af5c87780a8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "577/577 [==============================] - 13s 19ms/step - loss: 0.0386 - accuracy: 0.0754\n",
            "Epoch 2/20\n",
            "577/577 [==============================] - 10s 18ms/step - loss: 0.0233 - accuracy: 0.0792\n",
            "Epoch 3/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0229 - accuracy: 0.0873\n",
            "Epoch 4/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0224 - accuracy: 0.1118\n",
            "Epoch 5/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0218 - accuracy: 0.1321\n",
            "Epoch 6/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0213 - accuracy: 0.1441\n",
            "Epoch 7/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0209 - accuracy: 0.1558\n",
            "Epoch 8/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0205 - accuracy: 0.1634\n",
            "Epoch 9/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0202 - accuracy: 0.1690\n",
            "Epoch 10/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0200 - accuracy: 0.1764\n",
            "Epoch 11/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0198 - accuracy: 0.1812\n",
            "Epoch 12/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0196 - accuracy: 0.1887\n",
            "Epoch 13/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0194 - accuracy: 0.1928\n",
            "Epoch 14/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0192 - accuracy: 0.1972\n",
            "Epoch 15/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0190 - accuracy: 0.2030\n",
            "Epoch 16/20\n",
            "577/577 [==============================] - 10s 18ms/step - loss: 0.0188 - accuracy: 0.2075\n",
            "Epoch 17/20\n",
            "577/577 [==============================] - 10s 17ms/step - loss: 0.0186 - accuracy: 0.2128\n",
            "Epoch 18/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0185 - accuracy: 0.2193\n",
            "Epoch 19/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0183 - accuracy: 0.2238\n",
            "Epoch 20/20\n",
            "577/577 [==============================] - 9s 16ms/step - loss: 0.0181 - accuracy: 0.2320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f45bbee3890>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = ['mr', 'and', 'dursley', 'of', 'were', 'to']\n",
        "a = [ word_code(en.stem(onlylett.sub('', s[0])),sorted_words,250),\n",
        "     word_code(en.stem(onlylett.sub('', s[1])),sorted_words,250),\n",
        "     word_code(en.stem(onlylett.sub('', s[2])),sorted_words,250),\n",
        "     word_code(en.stem(onlylett.sub('', s[3])),sorted_words,250), \n",
        "     word_code(en.stem(onlylett.sub('', s[4])),sorted_words,250)]\n",
        "b = to_categorical(a, num_classes = 250)\n",
        "res = model.predict(np.array([b]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FoPl7Smg9BZ",
        "outputId": "3ed9c15d-24e0-4aca-ddd7-2c856c37fa70"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 530ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(sorted_words)[(-res[0]).argsort()[:5]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVnAGltG128Q",
        "outputId": "c547e059-e64a-4d7a-dfa3-45ecca536b80"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['to', 'the', 'in', 'and', 'on'], dtype='<U16')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(res[0],reverse=True)[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpeay7SA1_vs",
        "outputId": "f98181b6-10a4-4c01-89ac-5affec8d1bda"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18678398, 0.13137503, 0.05326851, 0.052650973, 0.04327776]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy with the LSTM model was mostly similar to the previous, but with some more epochs it would increase more than the other one. As we can see from the example above, with L = 5, the model can successfully predict the word `to` given the 5 previous words."
      ],
      "metadata": {
        "id": "SdHUAht23zbk"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}