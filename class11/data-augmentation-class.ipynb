{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras import models, regularizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import skimage.draw\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(directory, data=[], y_hat=[], label=0):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            img = matplotlib.image.imread(directory+file)\n",
    "            data.append(img)\n",
    "        y_hat = [label] * len(data)\n",
    "    return np.array(data), np.array(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/danbrice/keras-plot-history-full-report-and-grid-search\n",
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles, y_circles = [], []\n",
    "circles, y_circles = make_labels('shapes/circles/', data=circles, y_hat=y_circles)\n",
    "\n",
    "squares, y_squares = [], []\n",
    "squares, y_squares = make_labels('shapes/squares/', data=squares, y_hat=y_squares, label=1)\n",
    "\n",
    "triangles, y_triangles = [], []\n",
    "triangles, y_triangles = make_labels('shapes/triangles/', data=triangles, y_hat=y_triangles, label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(circles.shape, squares.shape, triangles.shape)\n",
    "print(y_circles.shape, y_squares.shape, y_triangles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((circles, squares, triangles))\n",
    "y = np.hstack((y_circles, y_squares, y_triangles)).reshape(-1, 1)\n",
    "y_cat = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "plt.imshow(circles[i])\n",
    "plt.show()\n",
    "plt.imshow(triangles[i])\n",
    "plt.show()\n",
    "plt.imshow(squares[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = triangles[3]\n",
    "rows, cols, ch = img.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation\n",
    "Rotation around center `(cx,cy)` by angle `deg` degrees, and scale the image by `f`\n",
    "\n",
    "`cv2.getRotationMatrix2D( (cx,cy), deg, f )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_mat = cv2.getRotationMatrix2D( (14,14), 70, 0.5 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timg = cv2.warpAffine( img, rot_mat, (cols, rows), borderValue=(1.,1.,1.) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(timg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine transformation\n",
    "Transform a triangle to an other triangle. `pts1` is transformed to `pts2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1 = np.float32([[5, 5], \n",
    "                   [20, 5],  \n",
    "                   [5, 20]]) \n",
    "  \n",
    "pts2 = np.float32([[1, 10], \n",
    "                   [20, 5],  \n",
    "                   [10, 25]]) \n",
    "  \n",
    "M = cv2.getAffineTransform(pts1, pts2) \n",
    "dst = cv2.warpAffine(img, M, (cols, rows), borderValue=(1.,1.,1.)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[0,0.1,0],[0.1,0.6,0.1],[0,0.1,0]])\n",
    "dst = np.clip(cv2.filter2D(img,-1,kernel),0,1)\n",
    "plt.imshow(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(10,10,figsize=(15,15))\n",
    "for i in range(100):\n",
    "    plt.subplot(10,10,i+1)\n",
    "    plt.imshow(triangles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK\n",
    "Using the single training images above (`circles[3], squares[3], trinagles[3]`), create a few hundred new training images using the transformations above. Use it as a training set for a convolutional neural network and test it on the original data set. Accuracy above 40-50% is nice! Hints:\n",
    " * I used 4 layers of convolutions and max pooling after each second\n",
    " * The dense hidden layer can be large ~100 nodes but always use regulariaztion overfitting in this case is suicide!\n",
    " * I have used only affine transformation on the rotated image, but you can try other things\n",
    " * I have used a weak image enhancement with `[[0,-e,0],[-e,1+4e,-e],[0,-e,0]]` matrix, with `e` around 0.25\n",
    " * After all transformations, I have rescaled the images to the range $[0:1]$\n",
    " * I have used normally distributed random numbers on all possible parameters of the affine transformations, see example below for possible problems.\n",
    " * Advice: plot the created images (see the command above) to see if they get similarly distorted to the ones above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normally distributed integer numbers\n",
    "General task: modify a number with an integer using normal distribution\n",
    "\n",
    "Solution: generate normally distributed float numbers and convert it to integer. Problem is that both `int(0.5)=0` and `int(-0.5)=0`. Thus make sure that the float numbers are always positive. In the second example below, you can see the high peak at 0 which is artificial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.random.normal(4.5,1.5,size=1000).astype(int),bins=np.arange(10)-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.random.normal(1.5,1.5,size=1000).astype(int),bins=np.arange(10)-4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
