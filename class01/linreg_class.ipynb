{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression example: Movie success prediction\n",
    "(M Mestyán, T Yasseri, J Kertész - PloS one, 2013)\n",
    "\n",
    "* Variables:\n",
    "  - [V] Number of views of the Wikipedia page\n",
    "  - [U] Number of editors of the Wikipedia page\n",
    "  - [E] Number of edits made on the Wikipedia page\n",
    "  - [R] Collaborative rigor of Wikipedia editing\n",
    "  - [T] <span style=\"color:red\">Number of theaters that screen the movie</span>\n",
    "* Time${=}0$ day of release\n",
    "* Coefficient of determination\n",
    "* Relative importance of parameters can be read\n",
    "* Coefficients also proportional to parameter importance\n",
    "<img src=\"movie.png\" width=\"640\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x[:,0]*7 - x[:,1]*3 + np.random.random() - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.scatter(x[:,0], x[:,1], y, marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model\n",
    "\n",
    "$$y_i=w_0+w_1x_i+w_2x_i^2+\\cdots+w_mx_i^m+\\varepsilon_i$$\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} y_1\\cr y_2\\cr \\vdots\\cr y_n \\end{pmatrix} =\n",
    "\\begin{pmatrix}\n",
    "1&x_1&x_1^2&\\dots &x_1^m\\cr\n",
    "1&x_2&x_2^2&\\dots &x_2^m\\cr\n",
    "\\vdots&\\vdots&\\vdots&\\ddots &\\vdots\\cr\n",
    "1&x_n&x_n^2&\\dots &x_n^m\\cr\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} w_1\\cr w_2\\cr \\vdots\\cr w_n \\end{pmatrix}\n",
    "+\n",
    "\\begin{pmatrix} \\varepsilon_1\\cr \\varepsilon_2\\cr \\vdots\\cr\n",
    "\\varepsilon_n \\end{pmatrix}\n",
    "$$\n",
    "Solve for $\\mathbf{w}$:\n",
    "$$\\mathbf{w}=(X^TX)^{-1}X^T \\mathbf{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve for w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = XXX\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.scatter(x[:,0], x[:,1], y, marker='o')\n",
    "ax.scatter(x[:,0], x[:,1], x[:,0] * XXX + x[:,1] * XXX, marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(x, y))\n",
    "print('coeffs:', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is it better?\n",
    "Reason internal linear regression also assumes a constant term add a contant term to x\n",
    "\n",
    "Implement it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic data\n",
    "Important columns (starting from 0)\n",
    " * 1: survived (1: yes, 0: no)\n",
    " * 2: passenger class\n",
    " * 4: gender\n",
    " * 5: age\n",
    "The 1 in the last columnt is for the constant part of the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"titanic.csv\",\"r\")\n",
    "f.readline() # header\n",
    "x = np.zeros((891,4), dtype=float)\n",
    "y = np.zeros(891,dtype=float)\n",
    "i = 0\n",
    "for line in f:\n",
    "    n = line.split(\";\")\n",
    "    y[i] = float(n[1])\n",
    "    if n[5].isdigit():\n",
    "        age = float(n[5])\n",
    "    else:\n",
    "        age = -1\n",
    "    x[i] = [float(n[2]), float(n[4]==\"male\"),age,1 ]\n",
    "    i += 1\n",
    "f.close()\n",
    "print(x[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    " * We have used -1 for unknown age. Replace it with the average age (averageof the known ones!)\n",
    " * Normalize the columns so that the coefficients can be compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[0:3],\"\\n---\\n\",y[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[:,0].mean(),x[:,1].mean(),x[:,2].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXX our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = model.score(x, y)\n",
    "print(r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('coeffs:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit XXX our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "Just for curiosity. For binary data it works better than linear regression.\n",
    "\n",
    "Binary output $Y$. Probability of $Y$ to happen is:\n",
    "$$p(Y=1)=\\frac{1}{1+\\exp{\\sum \\beta_i x_i}} $$\n",
    "<img src=\"lin_log_reg.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression().fit(x, y)\n",
    "r_sq = model.score(x, y)\n",
    "print(r_sq)\n",
    "print('coeffs:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
